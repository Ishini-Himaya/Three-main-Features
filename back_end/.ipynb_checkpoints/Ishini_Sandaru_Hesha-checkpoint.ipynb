{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "537e772a-38ae-44f6-8529-4dc50c2d0ab9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking Left\n",
      "looking up\n",
      "looking Right\n",
      "looking up\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking down\n",
      "looking up\n",
      "looking Right\n",
      "looking up\n",
      "Mobile phone detected!\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking up\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Forward\n",
      "looking up\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Forward\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "looking up\n",
      "Mobile phone detected!\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking Right\n",
      "Mobile phone detected!\n",
      "Mobile phone Not Detected Count reached over 100!\n",
      "Mobile phone Not Detected Count reached over 100!\n",
      "Mobile phone Not Detected Count reached over 100!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Forward\n",
      "looking up\n",
      "Face Not Detected Count reached over 100!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Mobile phone detected!\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking up\n",
      "Forward\n",
      "looking up\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m frame_gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mequalizeHist(frame_gray)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# Detect faces\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m faces \u001b[38;5;241m=\u001b[39m \u001b[43mface_cascade\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetectMultiScale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_gray\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(faces) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     69\u001b[0m     face_detected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Load the pre-trained face and eyes cascade classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_alt.xml')\n",
    "eyes_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "# Load the object detection model\n",
    "config_file = 'ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'\n",
    "frozen_model = 'frozen_inference_graph.pb'\n",
    "model = cv2.dnn_DetectionModel(frozen_model, config_file)\n",
    "class_labels = {}\n",
    "file_name = 'labels.txt'\n",
    "with open(file_name, 'rt') as fpt:\n",
    "    for idx, label in enumerate(fpt.read().splitlines()):\n",
    "        class_labels[idx] = label\n",
    "model.setInputSize(320, 320)\n",
    "model.setInputScale(1.0 / 127.5)\n",
    "model.setInputMean((127.5, 127, 5, 127.5))\n",
    "model.setInputSwapRB(True)\n",
    "\n",
    "# Initialize the video capture\n",
    "capture = cv2.VideoCapture(0)  # 0 represents the default camera\n",
    "\n",
    "# Initialize counters\n",
    "face_detected = False\n",
    "eyes_detected = False\n",
    "face_not_detected_count = 0\n",
    "eyes_not_detected_count = 0\n",
    "face_not_detected_over_100_count = 0\n",
    "eyes_not_detected_over_100_count = 0\n",
    "face_count = 0\n",
    "phone_detected = False\n",
    "phone_not_detected_count = 0\n",
    "phone_not_detected_over_100_count = 0\n",
    "\n",
    "# Create a DataFrame to store counts\n",
    "df = pd.DataFrame(columns=['Face_Not_Detected_Count', 'Eyes_Not_Detected_Count','Phone_Not_Detected_Count','Model_Prediction'])\n",
    "\n",
    "# Initialize Mediapipe face mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)\n",
    "\n",
    "# Variable to store the previous direction\n",
    "prev_direction = None\n",
    "\n",
    "while capture.isOpened():\n",
    "    start = time.time()  # Initialize start time\n",
    "\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    if frame is None:\n",
    "        print(\"--(!) No captured frame -- Break!\")\n",
    "        break\n",
    "\n",
    "    # Apply the face and eyes cascade classifiers\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.equalizeHist(frame_gray)\n",
    "\n",
    "    # Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "\n",
    "    if len(faces) == 0:\n",
    "        face_detected = False\n",
    "        face_not_detected_count += 1\n",
    "        if face_not_detected_count >= 100:\n",
    "            face_not_detected_over_100_count += 1\n",
    "            face_not_detected_count = 0  # Reset the counter\n",
    "            print(\"Face Not Detected Count reached over 100!\")\n",
    "        eyes_not_detected_count = 0  # Reset eyes counter when no face is detected\n",
    "        cv2.putText(frame, f\"No face detected ({face_not_detected_count} times)\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "        if face_not_detected_count >= 100:\n",
    "            df.loc[len(df)] = {'Face_Not_Detected_Count': 100, 'Eyes_Not_Detected_Count': 0}\n",
    "            face_not_detected_count = 0\n",
    "    else:\n",
    "        if not face_detected:\n",
    "            face_detected = True\n",
    "            face_not_detected_count = 0  # Reset the counter\n",
    "            face_count += 1\n",
    "            \n",
    "        for (x, y, w, h) in faces:\n",
    "            center = (x + w // 2, y + h // 2)\n",
    "            cv2.ellipse(frame, center, (w // 2, h // 2), 0, 0, 360, (255, 0, 255), 4)\n",
    "            face_roi = frame_gray[y:y + h, x:x + w]\n",
    "\n",
    "            # In each face, detect eyes\n",
    "            eyes = eyes_cascade.detectMultiScale(face_roi)\n",
    "            if len(eyes) == 0:\n",
    "                eyes_detected = False\n",
    "                eyes_not_detected_count += 1\n",
    "                if eyes_not_detected_count >= 100:\n",
    "                    eyes_not_detected_over_100_count += 1\n",
    "                    eyes_not_detected_count = 0  # Reset the counter\n",
    "                    print(\"Eyes Not Detected Count reached over 100!\")\n",
    "                cv2.putText(frame, f\"No eyes detected ({eyes_not_detected_count} times)\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "                if eyes_not_detected_count >= 100:\n",
    "                    df.loc[len(df)] = {'Face_Not_Detected_Count': 0, 'Eyes_Not_Detected_Count': 100}\n",
    "                    eyes_not_detected_count = 0\n",
    "            else:\n",
    "                if not eyes_detected:\n",
    "                    eyes_detected = True\n",
    "                    eyes_not_detected_count = 0  # Reset the counter\n",
    "                face_not_detected_count = 0  # Reset face counter when eyes are detected\n",
    "                for (ex, ey, ew, eh) in eyes:\n",
    "                    eye_center = (x + ex + ew // 2, y + ey + eh // 2)\n",
    "                    radius = round((ew + eh) * 0.25)\n",
    "                    cv2.circle(frame, eye_center, radius, (255, 0, 0), 4)\n",
    "\n",
    "    # Apply object detection\n",
    "    ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.55)\n",
    "    if len(ClassIndex) != 0:\n",
    "        for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):\n",
    "            if ClassInd <= 80:\n",
    "                label = class_labels.get(ClassInd - 1, 'Mobile phone')\n",
    "                if label == 'Mobile phone':\n",
    "                    phone_detected = True\n",
    "                    phone_not_detected_count = 0  # Reset the counter\n",
    "                    cv2.rectangle(frame, boxes, (255, 0, 0), 2)\n",
    "                    cv2.putText(frame, label, (boxes[0] + 10, boxes[1] + 40), cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, color=(0, 255, 0), thickness=2)\n",
    "                    # Increment the phone count if phone detection confidence is above 0.55\n",
    "                    if conf > 0.55:\n",
    "                        print(\"Mobile phone detected!\")\n",
    "                        model_prediction = \"Mobile phone detected\"\n",
    "                else:\n",
    "                    phone_detected = False\n",
    "                    phone_not_detected_count += 1\n",
    "                    if phone_not_detected_count >= 100:\n",
    "                        phone_not_detected_over_100_count += 1\n",
    "                        phone_not_detected_count = 0  # Reset the counter\n",
    "                        print(\"Mobile phone Not Detected Count reached over 100!\")\n",
    "                    model_prediction = \"Mobile phone not detected\"\n",
    "    else:\n",
    "        phone_detected = False\n",
    "        phone_not_detected_count += 1\n",
    "        if phone_not_detected_count >= 100:\n",
    "            phone_not_detected_over_100_count += 1\n",
    "            phone_not_detected_count = 0  # Reset the counter\n",
    "            print(\"Mobile phone Not Detected Count reached over 100!\")\n",
    "        model_prediction = \"No objects detected\"\n",
    "\n",
    "\n",
    "    # Apply Mediapipe face mesh\n",
    "    image = cv2.cvtColor(cv2.flip(frame, 1), cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = face_mesh.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Initialize the variables for face mesh\n",
    "    face_2d = []\n",
    "    face_3d = []\n",
    "    if results.multi_face_landmarks:\n",
    "        for face_landmarks in results.multi_face_landmarks:\n",
    "            face_2d.clear()  # Clear the list for each face\n",
    "            face_3d.clear()  # Clear the list for each face\n",
    "            \n",
    "            for idx, lm in enumerate(face_landmarks.landmark):\n",
    "                if idx == 33 or idx == 263 or idx == 1 or idx == 61 or idx == 291 or idx == 199:\n",
    "                    if idx == 1:\n",
    "                        nose_2d = (lm.x * image.shape[1], lm.y * image.shape[0])\n",
    "                        nose_3d = (lm.x * image.shape[1], lm.y * image.shape[0], lm.z * 3000)\n",
    "\n",
    "                    x, y = int(lm.x * image.shape[1]), int(lm.y * image.shape[0])\n",
    "\n",
    "                    face_2d.append([x, y])\n",
    "\n",
    "                    face_3d.append([x, y, lm.z])\n",
    "\n",
    "            face_2d = np.array(face_2d, dtype=np.float64)\n",
    "\n",
    "            face_3d = np.array(face_3d, dtype=np.float64)\n",
    "\n",
    "            focal_length = 1 * image.shape[1]\n",
    "\n",
    "            cam_matrix = np.array([[focal_length, 0, image.shape[0] / 2],\n",
    "                                   [0, focal_length, image.shape[1] / 2],\n",
    "                                   [0, 0, 1]])\n",
    "\n",
    "            dist_matrix = np.zeros((4, 1), dtype=np.float64)\n",
    "\n",
    "            success, rot_vec, trans_vec = cv2.solvePnP(face_3d, face_2d, cam_matrix, dist_matrix)\n",
    "\n",
    "            rmat, jac = cv2.Rodrigues(rot_vec)\n",
    "\n",
    "            angles, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rmat)\n",
    "\n",
    "            x = angles[0] * 360\n",
    "            y = angles[1] * 360\n",
    "            z = angles[2] * 360\n",
    "\n",
    "            direction = None  # Variable to store the current direction\n",
    "\n",
    "            if y < -10:\n",
    "                direction = \"looking Left\"\n",
    "            elif y > 10:\n",
    "                direction = \"looking Right\"\n",
    "            elif x < -10:\n",
    "                direction = \"looking down\"\n",
    "            elif x > 10:\n",
    "                direction = \"looking up\"\n",
    "            else:\n",
    "                direction = \"Forward\"\n",
    "\n",
    "            if direction != prev_direction:\n",
    "                print(direction)\n",
    "\n",
    "            prev_direction = direction  # Update the previous direction\n",
    "\n",
    "            nose_3d_projection, jacobian = cv2.projectPoints(nose_3d, rot_vec, trans_vec, cam_matrix, dist_matrix)\n",
    "\n",
    "            p1 = (int(nose_2d[0]), int(nose_2d[1]))\n",
    "            p2 = (int(nose_2d[0] + y * 10), int(nose_2d[1] - x * 10))\n",
    "\n",
    "            cv2.line(image, p1, p2, (255, 0, 0), 3)\n",
    "\n",
    "            cv2.putText(image, direction, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 2)\n",
    "            cv2.putText(image, \"x: \" + str(np.round(x, 2)), (500, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255))\n",
    "            cv2.putText(image, \"y: \" + str(np.round(y, 2)), (500, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255))\n",
    "            cv2.putText(image, \"z: \" + str(np.round(z, 2)), (500, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255))\n",
    "\n",
    "        end = time.time()\n",
    "        totaltime = end - start\n",
    "\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=image,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=drawing_spec,\n",
    "            connection_drawing_spec=drawing_spec\n",
    "        )\n",
    "\n",
    "    # Save the predictions to the DataFrame\n",
    "    df.loc[len(df)] = {'Face_Not_Detected_Count': face_not_detected_count, \n",
    "                        'Eyes_Not_Detected_Count': eyes_not_detected_count,\n",
    "                        'Phone_Not_Detected_Count': phone_not_detected_count,\n",
    "                        'Model_Prediction': model_prediction}\n",
    "\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Combined Module\", image)\n",
    "\n",
    "    # Show the result\n",
    "    cv2.imshow(\"Mobile Phone Detection\", frame)\n",
    "\n",
    "    # Break the loop if 'ESC' key is pressed\n",
    "    if cv2.waitKey(10) == 27:\n",
    "        break\n",
    "\n",
    "# Save the DataFrame to an Excel sheet\n",
    "df.to_excel('E:/2nd year/1st_semester/1. SUBJECTS/SDGP/2. Implementation_CW/All/data_sheet.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1bcb51-398e-41a1-a542-0871efeb1dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9cf022-1ff5-4c92-aa3f-0beadf0b7f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a76426-4527-4a17-8c52-b633e3b2fab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d43a8e5f-c28f-4708-b888-29a0ac813635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release video capture and close all OpenCV windows\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f499af-89f5-44fa-b550-da2e4e2c4791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
